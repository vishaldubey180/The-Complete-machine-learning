{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_file=r\"SMSSpamCollection.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=pd.read_csv(data_file,delimiter='\\t',header=None,names=['target','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here we have textual data which contain spam colelction, we have already used that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "stop = set(stopwords.words('english'))\n",
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words_sans_stop=[]\n",
    "    for word in words :\n",
    "        if word in stop:continue\n",
    "        words_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in words_sans_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_train,sd_test=train_test_split(sd,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=<function split_into_lemmas at 0x00000161530657B8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=3000,\n",
       "        max_features=None, min_df=20, ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=None, smooth_idf=True, stop_words=None,\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(sd_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=tfidf.transform(sd_train['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=tfidf.transform(sd_test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data,sd_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97932328, 0.02067672]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_data[6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ELLO BABE U OK?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sd_test['message'])[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we used to do \n",
    "\n",
    "but now we are aware of pipelines so we will create pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Python pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to create pipeline first we will import pipeline from sklearn.pipleline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1=Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(analyzer=split_into_lemmas,min_df=20,max_df=3000)),\n",
    "    ('classfier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "so this pipeline allows us to provide a list of tuples so basically this list contain a different tuples of action , which we want to pipeline performe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer=<function split_into_lemmas at 0x00000161530657B8>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=3000,\n",
       "        max_features=None, min_df=20, ngram_range=(1, 1), ...       vocabulary=None)), ('classfier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(sd_train['message'],sd_train['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use pipeline by using pipe.fit and will give the training data \n",
    "\n",
    "when we do pipe.fit it will actually run tfidf and classifer on this data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95823681, 0.04176319],\n",
       "       [0.99030404, 0.00969596],\n",
       "       [0.99119974, 0.00880026],\n",
       "       ...,\n",
       "       [0.94020892, 0.05979108],\n",
       "       [0.97748664, 0.02251336],\n",
       "       [0.0141158 , 0.9858842 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.predict_proba(sd_test['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about just one type of feature it is just having the text data \n",
    "\n",
    "let's say we have problem where we have numerical and catagorical data \n",
    "\n",
    "so in that case we can not directly apply tfidf vectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=r'Existing Base.csv'\n",
    "\n",
    "bd=pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF_NO</th>\n",
       "      <th>children</th>\n",
       "      <th>age_band</th>\n",
       "      <th>status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>occupation_partner</th>\n",
       "      <th>home_status</th>\n",
       "      <th>family_income</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>self_employed_partner</th>\n",
       "      <th>...</th>\n",
       "      <th>Investment Tax Saving Bond</th>\n",
       "      <th>Home Loan</th>\n",
       "      <th>Online Purchase Amount</th>\n",
       "      <th>Revenue Grid</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>Investment in Commudity</th>\n",
       "      <th>Investment in Equity</th>\n",
       "      <th>Investment in Derivative</th>\n",
       "      <th>Portfolio Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Zero</td>\n",
       "      <td>51-55</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Secretarial/Admin</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;17,500, &gt;=15,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wales</td>\n",
       "      <td>74.67</td>\n",
       "      <td>18.66</td>\n",
       "      <td>32.32</td>\n",
       "      <td>89.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Zero</td>\n",
       "      <td>55-60</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Retired</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;27,500, &gt;=25,000</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>North West</td>\n",
       "      <td>20.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Zero</td>\n",
       "      <td>26-30</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>North</td>\n",
       "      <td>98.06</td>\n",
       "      <td>31.07</td>\n",
       "      <td>80.96</td>\n",
       "      <td>171.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Zero</td>\n",
       "      <td>18-21</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Manual Worker</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;15,000, &gt;=12,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>West Midlands</td>\n",
       "      <td>4.10</td>\n",
       "      <td>14.15</td>\n",
       "      <td>17.57</td>\n",
       "      <td>-41.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Zero</td>\n",
       "      <td>45-50</td>\n",
       "      <td>Partner</td>\n",
       "      <td>Business Manager</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>&lt;30,000, &gt;=27,500</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.91</td>\n",
       "      <td>25.98</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>70.16</td>\n",
       "      <td>55.86</td>\n",
       "      <td>80.44</td>\n",
       "      <td>235.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   REF_NO children age_band                status        occupation  \\\n",
       "0       1     Zero    51-55               Partner     Manual Worker   \n",
       "1       2     Zero    55-60  Single/Never Married           Retired   \n",
       "2       3     Zero    26-30  Single/Never Married      Professional   \n",
       "3       5     Zero    18-21  Single/Never Married      Professional   \n",
       "4       6     Zero    45-50               Partner  Business Manager   \n",
       "\n",
       "  occupation_partner home_status      family_income self_employed  \\\n",
       "0  Secretarial/Admin    Own Home  <17,500, >=15,000            No   \n",
       "1            Retired    Own Home  <27,500, >=25,000            No   \n",
       "2              Other    Own Home  <30,000, >=27,500           Yes   \n",
       "3      Manual Worker    Own Home  <15,000, >=12,500            No   \n",
       "4            Unknown    Own Home  <30,000, >=27,500            No   \n",
       "\n",
       "  self_employed_partner        ...          Investment Tax Saving Bond  \\\n",
       "0                    No        ...                               19.99   \n",
       "1                    No        ...                                0.00   \n",
       "2                    No        ...                                0.00   \n",
       "3                    No        ...                                0.00   \n",
       "4                    No        ...                                0.00   \n",
       "\n",
       "  Home Loan Online Purchase Amount Revenue Grid  gender         region  \\\n",
       "0      0.00                   0.00            1  Female          Wales   \n",
       "1      0.00                   0.00            2  Female     North West   \n",
       "2      3.49                   0.00            2    Male          North   \n",
       "3      0.00                   0.00            2  Female  West Midlands   \n",
       "4     45.91                  25.98            2  Female       Scotland   \n",
       "\n",
       "   Investment in Commudity  Investment in Equity  Investment in Derivative  \\\n",
       "0                    74.67                 18.66                     32.32   \n",
       "1                    20.19                  0.00                      4.33   \n",
       "2                    98.06                 31.07                     80.96   \n",
       "3                     4.10                 14.15                     17.57   \n",
       "4                    70.16                 55.86                     80.44   \n",
       "\n",
       "   Portfolio Balance  \n",
       "0              89.43  \n",
       "1              22.78  \n",
       "2             171.78  \n",
       "3             -41.70  \n",
       "4             235.02  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                             10155\n",
       "children                               5\n",
       "age_band                              13\n",
       "status                                 5\n",
       "occupation                             9\n",
       "occupation_partner                     9\n",
       "home_status                            5\n",
       "family_income                         13\n",
       "self_employed                          2\n",
       "self_employed_partner                  2\n",
       "year_last_moved                       95\n",
       "TVarea                                14\n",
       "post_code                          10040\n",
       "post_area                           2039\n",
       "Average Credit Card Transaction     1411\n",
       "Balance Transfer                    2183\n",
       "Term Deposit                        1419\n",
       "Life Insurance                      3111\n",
       "Medical Insurance                   1589\n",
       "Average A/C Balance                 2223\n",
       "Personal Loan                       1760\n",
       "Investment in Mutual Fund           2470\n",
       "Investment Tax Saving Bond           832\n",
       "Home Loan                            884\n",
       "Online Purchase Amount              1319\n",
       "Revenue Grid                           2\n",
       "gender                                 3\n",
       "region                                13\n",
       "Investment in Commudity             3558\n",
       "Investment in Equity                3250\n",
       "Investment in Derivative            3796\n",
       "Portfolio Balance                   8317\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                               int64\n",
       "children                            object\n",
       "age_band                            object\n",
       "status                              object\n",
       "occupation                          object\n",
       "occupation_partner                  object\n",
       "home_status                         object\n",
       "family_income                       object\n",
       "self_employed                       object\n",
       "self_employed_partner               object\n",
       "year_last_moved                      int64\n",
       "TVarea                              object\n",
       "post_code                           object\n",
       "post_area                           object\n",
       "Average Credit Card Transaction    float64\n",
       "Balance Transfer                   float64\n",
       "Term Deposit                       float64\n",
       "Life Insurance                     float64\n",
       "Medical Insurance                  float64\n",
       "Average A/C Balance                float64\n",
       "Personal Loan                      float64\n",
       "Investment in Mutual Fund          float64\n",
       "Investment Tax Saving Bond         float64\n",
       "Home Loan                          float64\n",
       "Online Purchase Amount             float64\n",
       "Revenue Grid                         int64\n",
       "gender                              object\n",
       "region                              object\n",
       "Investment in Commudity            float64\n",
       "Investment in Equity               float64\n",
       "Investment in Derivative           float64\n",
       "Portfolio Balance                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here we got two more libraries that is base estimator and transformixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarTypeSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,vartype,ignore_var):\n",
    "        self.vartype=vartype\n",
    "        self.ignore_var=ignore_var\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return X.select_dtypes(self.vartype).drop(self.ignore_var,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here we create one class it is basically for selecting particular variable type \n",
    "it allows us tos elect particular varaible type \n",
    "it is taking input as baseestimator and transformixin \n",
    "\n",
    "now it require a littile intialization so as initialization it needs the variable type so in vartype we are having numeric type and object type \n",
    "these are only two types which we will be  having \n",
    "so we are giving eiter numeric or object \n",
    "\n",
    "and out of these we will have some ignore variable \n",
    "\n",
    "ignore variable is the variable which we want to get rid off \n",
    "\n",
    "so any varaible which we wanted to drop initially we can proide it as ignore for ex:refno\n",
    "\n",
    "next we will mention return type \n",
    "\n",
    "so in case of transforms we want to return the the datatypes and want to ignore the mentioned column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2ccb00b7300e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mget_dummies_PipeLineFriendly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq_cutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq_cutoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreq_cutoff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_cat_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class get_dummies_PipeLineFriendly(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,freq_cutoff=0):\n",
    "        self.freq_cutoff=freq_cutoff\n",
    "        self.var_cat_dict={}\n",
    "        \n",
    "    def fit(self,x,y=None):\n",
    "        data_cols=x.columns\n",
    "        for col in data_cols:\n",
    "            k=x[col].value_counts()\n",
    "            cats=k.index[k>self.freq_cutoff][:-1]\n",
    "            self.var_cat_dict[col]=cats\n",
    "        return self\n",
    "            \n",
    "    def transform(self,x,y=None):\n",
    "        dummy_data=x.copy()\n",
    "        for col in self.var_cat_dict.keys():\n",
    "            for cat in self.var_cat_dict[col]:\n",
    "                name=col+'_'+cat\n",
    "                dummy_data[name]=(dummy_data[col]==cat).astype(int)\n",
    "            del dummy_data[col]\n",
    "        return dummy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we are creating get dummies class which will create dummies varaible \n",
    "\n",
    "so we are mentioning freq cutoff which are used for creating dumm column \n",
    "\n",
    "then we are getting different columns \n",
    "\n",
    "and then we are getting count of diffrent categories \n",
    "\n",
    "and based on the count we are checking if the value is greater than mentioned freq cutoff \n",
    "\n",
    "if it is greater than then we will put it into var_cat-dict otherwise we won't \n",
    "\n",
    "in transforming part we have var_cat-dictkeys \n",
    "now based on these we get the column names and from each column we get each categories \n",
    "and from this categories we combine the column and convert it into dummy column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline,FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train,bd_test=train_test_split(bd,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=bd_train.drop('Revenue Grid',axis=1)\n",
    "x_test=bd_test.drop('Revenue Grid',axis=1)\n",
    "y_train=bd_train['Revenue Grid']\n",
    "y_test=bd_test['Revenue Grid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REF_NO                               int64\n",
       "children                            object\n",
       "age_band                            object\n",
       "status                              object\n",
       "occupation                          object\n",
       "occupation_partner                  object\n",
       "home_status                         object\n",
       "family_income                       object\n",
       "self_employed                       object\n",
       "self_employed_partner               object\n",
       "year_last_moved                      int64\n",
       "TVarea                              object\n",
       "post_code                           object\n",
       "post_area                           object\n",
       "Average Credit Card Transaction    float64\n",
       "Balance Transfer                   float64\n",
       "Term Deposit                       float64\n",
       "Life Insurance                     float64\n",
       "Medical Insurance                  float64\n",
       "Average A/C Balance                float64\n",
       "Personal Loan                      float64\n",
       "Investment in Mutual Fund          float64\n",
       "Investment Tax Saving Bond         float64\n",
       "Home Loan                          float64\n",
       "Online Purchase Amount             float64\n",
       "Revenue Grid                         int64\n",
       "gender                              object\n",
       "region                              object\n",
       "Investment in Commudity            float64\n",
       "Investment in Equity               float64\n",
       "Investment in Derivative           float64\n",
       "Portfolio Balance                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe=Pipeline([\n",
    "    ('cat_var',VarTypeSelector(['object'],ignore_var=['post_code','post_area'])),\n",
    "    ('dummies',get_dummies_PipeLineFriendly(100))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will create pipeline \n",
    "\n",
    "so first pipeline which we will be craeting is catgorical pipeline\n",
    "\n",
    "it contain cat_var which contain varselector , it is selcting object datatype and ignoring postcode and post area\n",
    "\n",
    "next we are getting dumies and for dummmies we are fixing the frequency value as 100\n",
    "\n",
    "so first it will run catagorical varaible and then push all catagorical varaible into dummy varaible function and then it will generate dummy varaible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2=Pipeline([\n",
    "    ('features',FeatureUnion([\n",
    "        ('cat_pipe',cat_pipe),\n",
    "        ('num_var',VarTypeSelector(['int64','float64'],ignore_var=['REF_NO']))\n",
    "        \n",
    "    ])),\n",
    "    ('clf',LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it will create next pipeline \n",
    "\n",
    "it apllies featureunion function \n",
    "\n",
    "so in feature union it will first run the cat pipeline \n",
    "while running the cat pipeline it will create catagorical varaible \n",
    "then it will get the num_var \n",
    "\n",
    "once we have these two then feature union will run \n",
    "\n",
    "and the result of the feature union will pass to the logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MansiGupta\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('cat_pipe', Pipeline(memory=None,\n",
       "     steps=[('cat_var', VarTypeSelector(ignore_var=['post_code', 'post_area'], vartype=['object'])), ('dummies', get_dummies_PipeLineFriendly(freq_cutoff=100))])), ('num_var', VarTypeSelector(ig...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00352334, 0.99647666],\n",
       "       [0.00623159, 0.99376841],\n",
       "       [0.00768033, 0.99231967],\n",
       "       ...,\n",
       "       [0.43372072, 0.56627928],\n",
       "       [0.17600561, 0.82399439],\n",
       "       [0.01433096, 0.98566904]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save python objects to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_model_pipeline.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe1,'my_model_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(message):\n",
    "    message=message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words_sans_stop=[]\n",
    "    for word in words :\n",
    "        if word in stop:continue\n",
    "        words_sans_stop.append(word)\n",
    "    return [lemma.lemmatize(word) for word in words_sans_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel=open('my_model_pipeline.pkl','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=joblib.load(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_msg=['I‘m going to try for 2 months ha ha only joking',\n",
    "        '''Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. \n",
    "        Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's''']\n",
    "my_df=pd.DataFrame({'message':my_msg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0    I‘m going to try for 2 months ha ha only joking\n",
       "1  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95929988, 0.04070012],\n",
       "       [0.01743449, 0.98256551]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba(my_df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
